---
title: "Projet d’Algorithmique : Classification des séries temporelles à l'aide Dynamic Time Wraping"
author: "Sarah Eliko, Fatimah-Zara Aklila , Samira Sonfack"
date: "`r format(Sys.Date(), '%d %B %Y')`"
output:
  html_document:
    toc: true
    toc_depth: '2'
    df_print: paged
  pdf_document:
    toc: true
    toc_depth: 2
    number_sections: true
    highlight: tango
    latex_engine: xelatex
geometry: margin=2.5cm
fontsize: 12pt
---

```{r setup, include=FALSE}
# Installer le package depuis GitHub si nécessaire
if (!requireNamespace("ProjetM2Algo", quietly = TRUE)) {
  if (!requireNamespace("remotes", quietly = TRUE))
    install.packages("remotes")
  remotes::install_github("samirasonfack/ProjetM2Algo/")
}

# Charger le package
library(ProjetM2Algo)
```
\newpage

# Introduction

Le mathématicien Al-Khwarizmi a rédigé de nombreux travaux qui furent traduits au XIIe siècle. C’est d’ailleurs de son nom que provient le mot « algorithme ».
Un algorithme peut être défini comme un enchaînement d’instructions logiques permettant de résoudre un problème. Il constitue la traduction d’un raisonnement en un pseudo-code. Mais dans quelles circonstances construit-on un algorithme, et comment intervient l’algorithmique dans ce processus ? Lorsqu’une problématique nécessite une méthode de calcul efficace, il devient nécessaire d’adopter une démarche algorithmique. L’algorithmique regroupe l’ensemble des méthodes génériques permettant de résoudre des problèmes. Elle s’intéresse aussi à l’étude de la complexité de ces méthodes, c’est-à-dire à leur rapidité, leur efficacité et leur capacité à s’adapter à différents cas. Autrement dit, elle ne se limite pas à la simple écriture d’un algorithme, mais vise à concevoir la meilleure approche possible pour atteindre un résultat fiable et optimisé.
Aujourd’hui, au XXIe siècle, de nombreux mathématiciens et informaticiens ont inventé, amélioré et publié diverses méthodes de résolution. Ces avancées nous permettent de disposer d'outils conceptuels pour résoudre des problèmes complexes.

La résolution d’une problématique passe d’abord par l’évaluation de la complexité du problème, puis par le choix d’une méthode adaptée, d’où l’utilisation de l’algorithmique. Vient ensuite la construction du programme à l’aide de l’algorithme et en utilisant un langage de programmation choisi. Après l’exécution du programme, un résultat concret est obtenu, traduisant la pertinence de la méthode employée.


## Contexte

Une série temporelle est une suite chronologique de valeurs numériques.
Les séries temporelles sont utilisées dans plusieurs domaines, comme en médecine, par exemple pour le suivi d’une constante vitale au cours du temps, ou encore en finance pour le suivi du cours d’une action.
Dans ces deux disciplines, l’analyse de ces séries temporelles peut être cruciale, notamment pour le diagnostic d’une anomalie ou de la détection d’un comportement particulier.
Dans notre cas, nous allons nous intéresser à une méthode permettant de classifier les séries temporelles.
Dans un premier temps, nous allons utiliser deux algorithmes qui vont nous permettre de comparer deux séries entre elles.
Plus précisément, nous allons utiliser l’algorithme DTW, puis une amélioration de cet algorithme appelée FastDTW.
Enfin, nous choisirons le meilleur algorithme pour la classification.



```{r, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Dynamic Time Warping

L’algorithme Dynamic Time Warping (DTW) ou Déformation Temporelle Dynamique, permet de mesurer la similarité entre deux séries temporelles qui peuvent différer en vitesse ou en phase.  

Cette méthode aligne de manière non linéaire deux séquences temporelles pour obtenir la correspondance optimale entre leurs éléments.

Soient deux séries temporelles :
\[
X = (x_1, x_2, \dots, x_n)
\quad \text{et} \quad
Y = (y_1, y_2, \dots, y_m)
\]

On définit la distance D entre deux points correspondants :
\[
D(i,j) = (x_i - y_j)^2
\]

Le but du DTW est de construire une matrice de coût cumulatif \( C \), où chaque élément \( C(i,j) \) représente le coût minimal d’alignement des sous-séquences \( (x_1, \dots, x_i) \) et \( (y_1, \dots, y_j) \).  
Cette matrice est calculée récursivement selon :
\[
C(i,j) =
\begin{cases}
D(1,1), & \text{si } i = 1, j = 1, \\[8pt]
D(i,1) + C(i-1,1), & \text{si } j = 1, i > 1, \\[8pt]
D(1,j) + C(1,j-1), & \text{si } i = 1, j > 1, \\[8pt]
D(i,j) + \min \big( C(i-1,j), \; C(i,j-1), \; C(i-1,j-1) \big), & \text{sinon.}
\end{cases}
\]

L’objectif de la méthode DTW est de trouver le chemin optimal qui minimise la distance totale entre les deux séries temporelles.  

La distance DTW finale est alors donnée par :
\[
DTW(n,m) = \min_{\pi} \sum_{(i,j) \in \pi} D(i,j)
\]
où \( \pi \) désigne l’ensemble des chemins de warping valides reliant les points \((1,1)\) et \((n,m)\).

Dans la pratique, cette distance correspond à la valeur du dernier élément de la matrice de coût cumulatif :
\[
DTW(X,Y) = C(n,m)
\]

## Algorithme du DTW

L’algorithme DTW repose sur la programmation dynamique.  

Il consiste à remplir progressivement la matrice de coût cumulé \( C \).

\begin{verbatim}
Algorithme DTW(x, y):
1. Initialiser D[i,j] = |x_i - y_j|
2. Initialiser C[1,1] = D[1,1]
3. Remplir la première ligne et la première colonne de C
4. Pour i=2..n, j=2..m :
     C[i,j] = D[i,j] + min(C[i-1,j-1], C[i-1,j], C[i,j-1])
5. Rétrotraçage pour obtenir le chemin optimal
6. Retourner C, traceback, path 
\end{verbatim}

Path correspond au chemin optimal. 
La complexité en temps de l’algorithme DTW est de l’ordre de $O(NM)$.




## Exemple d'application

Considérons les deux séries temporelles suivantes :
\[
X = (1, 2, 3, 4)
\quad \text{et} \quad
Y = (1, 1, 2, 3, 5)
\]

Calcul de la matrice de distances locales \( D(i,j) \) :

\[
D =
\begin{bmatrix}
0 & 0 & 1 & 4 & 16 \\
1 & 1 & 0 & 1 & 9 \\
4 & 4 & 1 & 0 & 4 \\
9 & 9 & 4 & 1 & 1 \\
\end{bmatrix}
\]

Calcul de la matrice de coût cumulatif \( C(i,j) \) :

En remplissant la matrice pas à pas, on obtient :

\[
C =
\begin{bmatrix}
0 & 0 & 1 & 5 & 21 \\
1 & 1 & 0 & 1 & 10 \\
5 & 5 & 1 & 0 & 4 \\
14 & 14 & 5 & 1 & 2 \\
\end{bmatrix}
\]

La distance DTW entre \( X \) et \( Y \) est donnée par le dernier élément de la matrice :
\[
DTW(X,Y) = C(4,5) = 2
\]

Cette valeur faible indique que les deux séries sont similaires, même si elles ne sont pas parfaitement alignées temporellement.  

Le DTW a « déformé » le temps pour trouver un alignement optimal entre les points de \( X \) et \( Y \).


```{r}

x <- c(1, 3, 4, 9)
y <- c(1, 3, 7, 8, 9)
dtw_result <- dtw(x, y)
dtw_result
```

Nous cherchons maintenant à retrouver expérimentalement la complexité de l’algorithme DTW.
Lorsque les deux séries ont la même longueur \(n\), le temps d'exécution peut alors s’écrire sous la forme :

\[
T(n) = C \cdot n^2,
\]

où \(C\) est une constante correspondant au coût d’un calcul élémentaire. Cette constante ne dépend pas de \(n\).

Pour analyser la complexité à partir des mesures expérimentales, nous traçons le graphique
en échelle log-log. En prenant le logarithme de l’expression précédente, on obtient :

\[
\log T(n) = \log C + 2 \log n.
\]

Cette équation est de la forme d’une droite,
dont l’ordonnée à l’origine est \(\log C\) et dont la pente vaut \(2\).
Ainsi, si le graphique \(\log(n)\) -- \(\log(T)\) présente une pente
proche de \(2\), cela confirme expérimentalement la complexité quadratique
théorique du DTW.


### Simulation de la complexité

```{r}
# R
res <- simulation_dtw(debut = 10, fin = 500, pas = 10)
res$pente

```

```{r}
# C++
res <- simulation_dtw_rcpp(debut = 10, fin = 1000, pas = 10)
res$pente
```


## Algorithme du DTW avec bande de Sakoe Chiba fixe - Sakoe Chiba Band
<<<<<<< HEAD
=======


L’algorithme de **Sakoe–Chiba** introduit une contrainte locale appelée **bande de Chiba** afin de limiter les déformations autorisées lors du calcul du *Dynamic Time Warping* (DTW). Dans la formulation classique de la DTW, la matrice de coût est entièrement parcourue, ce qui conduit à une complexité temporelle en $O(N^2)$ pour deux signaux de longueur $N$.

Or lorsqu'on applique l'algorithme sur la même série on voit que le chemin optimal correspond à la diagonale et s'en éloigne d'autant plus que les séries diffèrent. La bande de Chiba impose que l’alignement optimal reste à l’intérieur d’une fenêtre de largeur prédéfinie autour de la diagonale principale.Une variante propose une fenêtre mobile sous forme de matrice dde "région":
- pour un point $(i,j)$, seules les cellules telles que  
  \[
  |i - j| \leq \text{radius}
  \]  
  sont considérées ; 
  
  On considèrera ici à **une taille de bande fixe**  **radius** dans toutes les directions. Ainsi, seuls les coûts des cellules situées dans cette zone restreinte sont évalués.

Grâce à cette contrainte, le nombre d’opérations nécessaires est considérablement réduit, faisant passer la complexité temporelle à :

$$
O(N \cdot w)
$$

où $w$ est la demi-largeur de la bande, généralement beaucoup plus petite que $N$.

En limitant les correspondances possibles, l’algorithme améliore non seulement l’efficacité computationnelle, mais également la robustesse de l’alignement, tout en conservant une bonne précision lorsque les signaux ne présentent pas de fortes distorsions temporelles.


#### Application : comparaison de cours de bourse des stocks d'une entreprise et d'un stock de matière première (pétrole) 

**Problématique** : Les séries sont à des fréquences différentes. Déterminer l'appartenance d'une entreprise à un secteur , évaluer analytiquement la corrélation entre les cours de bourse
```{r}


###  Charge les données depuis le package
path_stock <- system.file("extdata", "stock.csv", package = "ProjetM2Algo")
path_com <- system.file("extdata", "commodity.csv", package = "ProjetM2Algo")

df_stock <- read.csv(path_stock)
df_com <- read.csv(path_com)

df_stock$Date <- as.Date(df_stock$Date)
df_com$Date <- as.Date(df_com$Date)



X <- df_stock$Close
Y <- df_com$Close
radius1 <- 100
radius2 <- 500

dtw_result1 <- dtw_sakoe_chiba_rcpp(X, Y, radius = radius1)
dtw_result2 <- dtw_sakoe_chiba_rcpp(X, Y, radius = radius2)

#Indices pour radius1
path1 <- dtw_result1$path
idx_x1 <- sapply(path1, `[[`, 1)
idx_y1 <- sapply(path1, `[[`, 2)

aligned_X1 <- X[idx_x1]
aligned_Y1 <- Y[idx_y1]

df_aligned1 <- data.frame(
  Index = seq_along(aligned_X1),
  Stock = aligned_X1,
  Commodity = aligned_Y1 
)

# indices pour radius2
path2 <- dtw_result2$path
idx_x2 <- sapply(path2, `[[`, 1)
idx_y2 <- sapply(path2, `[[`, 2)

aligned_X2 <- X[idx_x2]
aligned_Y2 <- Y[idx_y2]

df_aligned2 <- data.frame(
  Index = seq_along(aligned_X2),
  Stock = aligned_X2,
  Commodity = aligned_Y2 
)

df_before <- full_join(
  df_stock %>% rename(Stock = Close),
  df_com %>% rename(Commodity = Close),
  by = "Date"
)

plot_before <- ggplot(df_before, aes(x = Date)) +
  geom_line(aes(y = Stock, color = "Stock")) +
  geom_line(aes(y = Commodity, color = "Commodity")) +
  labs(title = "1. Avant DTW : Séries Brutes",
       y = "Prix de Clôture",
       color = "Série") +
  theme_minimal() +
  scale_color_manual(values = c("Stock" = "blue", "Commodity" = "red"))

#radius1
plot_after1 <- ggplot(df_aligned1, aes(x = Index)) +
  geom_line(aes(y = Stock, color = "Stock")) +
  geom_line(aes(y = Commodity, color = "Commodity")) +
  labs(title = paste("2. Après DTW : Séries Alignées (radius =", radius1, ")"),
       x = paste("Indice Alignement (L:", length(aligned_X1), ")"),
       y = "Prix de Clôture (Aligné)",
       color = "Série") +
  theme_minimal() +
  scale_color_manual(values = c("Stock" = "blue", "Commodity" = "red"))

#radius2
plot_after2 <- ggplot(df_aligned2, aes(x = Index)) +
  geom_line(aes(y = Stock, color = "Stock")) +
  geom_line(aes(y = Commodity, color = "Commodity")) +
  labs(title = paste("3. Après DTW : Séries Alignées (radius =", radius2, ")"),
       x = paste("Indice Alignement (L:", length(aligned_X2), ")"),
       y = "Prix de Clôture (Aligné)",
       color = "Série") +
  theme_minimal() +
  scale_color_manual(values = c("Stock" = "blue", "Commodity" = "red"))

# =======================================================
# 6. Display plots side by side
# =======================================================
gridExtra::grid.arrange(plot_before, plot_after1, plot_after2, ncol = 3)

```

```{r}
length(aligned_X)
length(aligned_Y)

```


### Calcul théorique de complexité


Soit deux séries temporelles de longueur égale $N$.  

Avec **une bande de Chiba de radius $r$** (fenêtre fixe autour de la diagonale), seules les cellules telles que $|i - j| \le r$ sont calculées.  

Chaque ligne de la matrice contient au maximum $2r + 1$ cellules évaluées. La complexité devient donc :

$$
T_{\text{DTW_bande}}(N, r) = O(N \cdot (2r + 1)) \approx O(N \cdot r)
$$

où $r$ est généralement beaucoup plus petit que $N$.  

Ainsi, la réduction de la complexité par rapport au DTW classique est significative, surtout pour de grandes séries temporelles.

---

### Représentation log-log

Pour visualiser la complexité, on peut utiliser une **échelle log-log** :

$$
x = \log(N), \quad y = \log(T(N))
$$

- Pour le **DTW avec bande fixe** :  

$$
y = \log(N \cdot r) = \log(r) + \log(N) \approx \log(N) \quad \text{si $r$ constant}
$$

En pratique :  

Sur un graphique log-log, la **pente de la droite** correspond à l’exposant de $N$. Donc une pente ≈ 1 
 
   



###Simulation de la complexité temporelle

```{r}
n_values <- round(exp(seq(log(50), log(5000), length.out = 15)))
res1 <- simulate_dtw_sakoe_chiba(
      n_values,
      algo_r = dtw_sakoe_chiba,
      algo_rcpp = dtw_sakoe_chiba_rcpp,
      radius = 2,
      plot = TRUE
      )
```

```{r}
# Simulation 2 (Radius = 5)
res2 <- simulate_dtw_sakoe_chiba(
    n_values,
    algo_r = dtw_sakoe_chiba,
    algo_rcpp = dtw_sakoe_chiba_rcpp,
    radius = 5, # Changer le rayon
    plot = TRUE
)
```


```{r}
library(gridExtra)

gridExtra::grid.arrange(
    res1$plot, 
    res2$plot, 
    ncol = 2,
    top = "Comparaison de la Complexité R vs Rcpp sous différentes contraintes"
)
```
```{r}

# Affichage des pentes 
cat(" Pentes de Complexité par Implémentation :\n")
cat("\n* Pente R (Radius 1) : **", round(res1$slope_r, 4), "**")

cat("\n* Pente R (Radius 2) : **", round(res2$slope_r, 4), "**")

cat("\n* Pente Rcpp (Radius 1) : **", round(res1$slope_rcpp, 4), "**")

cat("\n* Pente Rcpp (Radius 2) : **", round(res2$slope_rcpp, 4), "**")

```
On voit conformément au résultat théorique attendu qu'on a une complexité $O(N)$ avec un pente très proche de 1 pour le code Rcpp et légèrement supérieure à 1 en R. On vérifie également que la **complexité varie peu selon le radius** . Les résultats autour de **1.45** pour le code R mettent en évidence les faiblesses de l'interpréteur R qui introduit un temps de calcul supplémentaire qui augmente avec la valeur de N. Rcpp à contrario est compilé et facilite les calculs lourds tels que les boucles imbriquées.






>>>>>>> 781c4db1ecfd47a5c4271796d3a3dabbd63e0b89



## Segmental DTW 
Le segmental DTW (SDTW) est une variante du DTW classique utilisée pour comparer deux séries temporelles par segments plutôt que globalement.

Il repose sur 3 idées principales :
-	Au lieu de comparer toute la série X avec toute la série Y, on découpe Y en segments de longueur fixe. 
-	On effectue le DTW sur chaque segment séparément. 
-	Ensuite, on combine les distances segmentales pour obtenir une distance globale ou un alignement segment par segment.

### Etapes de Segmental DTW 
#### Segmentation 
Dans le code, la première étape consiste à diviser la série serie2 en segments de longueur fixe segment_length :
```{r}
serie1 <- c(1, 3, 4, 9, 8)
serie2 <- c(1, 2, 3, 4, 7, 8, 9, 10)
segment_length <- 2
segments <- segment_series(serie2, segment_length)

```

Cette étape permet de traiter serie2 par blocs, ce qui est plus efficace et facilite l’analyse locale.

#### Calcul du DTW pour chaque segment 
Ensuite, pour chaque segment, le code calcule le DTW entre serie1 complète et les segments courants de la serie2 :
```{r}
dtw_segments <- compute_segment_dtw(serie1, serie2, segments)
dtw_segments[1]
```
Chaque élément de dtw_segments contient la matrice des coûts cumulés frame-level, le chemin optimal et la matrice de traces pour reconstruire le chemin. 
Cette étape correspond à l'alignement local segment par segment, au lieu d'un DTW global sur toute la série 2. 

#### Calcul des coûts segmentaux 
Pour combiner les distances locales, le code extrait la dernière ligne de chaque matrice DTW pour chaque segment :

```{r}
seg_cost_list <- compute_segment_level_cost(dtw_segments)
seg_cost_list
```
La dernière ligne de DTW_matrix représente le coût pour atteindre chaque frame de serie1 à la fin du segment.
seg_cost_list devient la base pour calculer le cumulative cost global segment-level.

#### Cumulative cost des segments
Le code cumule les coûts des segments pour obtenir la distance globale :
```{r}
n_seg <- length(segments)
n_len <- length(serie1)
cum_cost <- matrix(Inf, nrow=n_seg, ncol=n_len)
cum_cost[1, 1:length(seg_cost_list[[1]])] <- seg_cost_list[[1]]

for(i in 2:n_seg){
  seg_cost <- seg_cost_list[[i]]
  for(j in 1:length(seg_cost)){
    min_prev <- min(cum_cost[i-1, j:n_len])
    cum_cost[i,j] <- seg_cost[j] + min_prev
  }
}

cum_cost
```

cum_cost[i,j] : coût minimal pour atteindre la position j dans serie1 après avoir traité i segments de serie2.

On effectue une recherche du minimum cumulatif sur les positions restantes pour connecter les segments.

#### Backtrace segment-level
Une fois la matrice cumulative calculée, on retrace le chemin optimal segment par segment. Cette étape permet de retrouver la séquence optimale de segments qui minimise la distance globale.
```{r}
path_seg <- list()
i <- n_seg
j <- which.min(cum_cost[n_seg, ])
while(i > 0){
  path_seg <- append(list(c(i,j)), path_seg)
  if(i==1) break
  j <- which.min(cum_cost[i-1, j:n_len])
  i <- i-1
}
path_seg
```


#### Reconstruction du chemin frame-level final et calcul de la distance de DTW

Enfin, le code reconstitue le chemin frame-level global à partir des chemins de chaque segment et retourne la distance DTW finale.

```{r}
result <- segmental_dtw_two_series(serie1, serie2, segment_length = 2)

cat("Distance DTW finale segmentale :", result$dtw_distance, "\n")
cat("Chemin frame-level final :\n")
print(result$final_path)
```


#### Evaluation de la compléxité de Segmental DTW
Soient deux séries de longueurs n et m, et un segment de longueur L. 
Si la série cible est partitionnée en 
$$
S = \lceil m / L \rceil
$$
segments, la complexité totale du **Segmental DTW** s’écrit :

$$
O(S \cdot n \cdot L) = O(n \cdot m)

$$
Ce qui correspond à la complexité théorique du DTW global, mais avec plusieurs avantages pratiques :
- **Mémoire optimisée :** seules des matrices de taille n×L sont allouées à chaque étape, limitant l’usage de la mémoire vive.

- **Possibilité de parallélisation :** chaque segment peut être traité indépendamment, ouvrant la voie à des accélérations sur architectures multi-cœurs.

- **Alignements locaux précis :** le découpage segmental permet de capturer des correspondances locales qui pourraient être diluées dans un DTW global.

#### Test de la complexité :
```{r}
res_complexity <- segmental_dtw_complexity()
print(paste("Exposant empirique estimé :", round(res_complexity$slope, 2)))
```

"Exposant empirique estimé : 1.76" Cette valeur de pente confirme que la méthode est très efficace pour de longues séries segmentées, tout en restant fidèle à sa complexité théorique.
